{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XfRlesI9ekPi"
      },
      "source": [
        "TODO list in 'deine data collactor' part\n",
        "1. json 파일에서 image size (height, width) 추가로 저장해서  read_ocr_core_engine() 에서 사용하기\n",
        "2. Dataset() class __init()__ 에서 label 불어로는 것 공부하여 적용하기 --> 찬영님이 하시는중\n",
        "3. user_prompt RvlCdipDataset.__get_item__() 부분에서 어떻게 집어넣을 지 생각해보기 --> 찬영님이 하시는중\n",
        "4. DataCollactor class 구현"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb-9YdQ_Bc16"
      },
      "source": [
        "#import module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfJa2S6OBVU1",
        "outputId": "11972c9f-1635-4050-9c93-6a69cb6665ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xml_to_dict\n",
            "  Downloading xml_to_dict-0.1.6-py3-none-any.whl (3.6 kB)\n",
            "Installing collected packages: xml_to_dict\n",
            "Successfully installed xml_to_dict-0.1.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ],
      "source": [
        "!pip install xml_to_dict #https://github.com/xthehatterx/xml_to_dict\n",
        "!pip install sentencepiece\n",
        "!pip install konlpy\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yUGKpQyEBiXt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fwZmM4-t86On"
      },
      "outputs": [],
      "source": [
        "from transformers.tokenization_utils import PreTrainedTokenizer\n",
        "from transformers.tokenization_utils_base import PaddingStrategy\n",
        "from transformers.tokenization_utils_fast import PreTrainedTokenizerFast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dELA-1G75TJb"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import json\n",
        "import math\n",
        "from io import BytesIO\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import xml_to_dict\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QQASXvTEBipZ"
      },
      "source": [
        "#own location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1BJzRYKBkP4",
        "outputId": "d6ad86fa-c7e1-419c-e9bb-68fc985d1a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/산학_테스트\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/ColabNotebooks/산학_테스트\n",
        "xml_sample_loc = 'xml_sample_20230519.csv'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iUJgovoVflQi"
      },
      "source": [
        "# pre-training tokenizer part (2023.06.23. revised)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "12wBJAggBwBt"
      },
      "source": [
        "##get 중복없는 keyword in xml sample file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtZiIGF8Bzxd"
      },
      "outputs": [],
      "source": [
        "xml_sample = pd.read_csv(xml_sample_loc)\n",
        "keyword = xml_sample['keyword']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mI5hrU4SB5n-"
      },
      "outputs": [],
      "source": [
        "#get 중복 없는 keyword\n",
        "keyword_unique = []\n",
        "\n",
        "for i in range(len(keyword)):\n",
        "  keyword_unique+=keyword[i].split('|')\n",
        "\n",
        "keyword_unique = list(set(keyword_unique))\n",
        "\n",
        "print(len(keyword_unique) )\n",
        "print(keyword_unique[:20])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YY6uQxryCF0X"
      },
      "source": [
        "##xml to json (2023.06.23. revised)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7jUZ5m6BCHFD"
      },
      "outputs": [],
      "source": [
        "#same with https://github.com/miridi-sanhak/model/blob/main/preprocessing.py\n",
        "\n",
        "import json\n",
        "import math\n",
        "from io import BytesIO\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import xml_to_dict\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "def process_bbox(XML_BBOX, IM_SIZE, SHEET_SIZE, angle, center):\n",
        "    RATIO = IM_SIZE[0] / SHEET_SIZE[0]\n",
        "    x1, y1, x2, y2 = map(float, XML_BBOX)\n",
        "    x1, y1, x2, y2 = (x1 * RATIO, y1 * RATIO, x2 * RATIO, y2 * RATIO)\n",
        "    center = (center[0] * RATIO, center[1] * RATIO)\n",
        "\n",
        "    if angle != 0:\n",
        "        angle = 360 - angle\n",
        "        angle = math.radians(angle)\n",
        "        # Calculate the center point of the bbox\n",
        "        center_x, center_y = center\n",
        "        # Calculate the distance from the center to each corner of the bbox\n",
        "        distance_x = (x1 - center_x)\n",
        "        distance_y = (y1 - center_y)\n",
        "        # Apply rotation to the distances\n",
        "        new_distance_x = distance_x * math.cos(angle) - distance_y * math.sin(angle)\n",
        "        new_distance_y = distance_x * math.sin(angle) + distance_y * math.cos(angle)\n",
        "        # Calculate the new corners after rotation\n",
        "        x1 = center_x + new_distance_x\n",
        "        y1 = center_y + new_distance_y\n",
        "        x2 = center_x - new_distance_x\n",
        "        y2 = center_y - new_distance_y\n",
        "\n",
        "    x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))\n",
        "\n",
        "    return x1, y1, x2, y2\n",
        "\n",
        "def get_render_bbox(text):\n",
        "    if text['RenderPos'] == None:\n",
        "        return []\n",
        "    render_pos = json.loads(text['RenderPos'])\n",
        "    render_bbox = []\n",
        "\n",
        "    left, top, right, bottom = map(float, text['Position'].values())\n",
        "\n",
        "    for render in render_pos['c']:\n",
        "        x, a, w, y = map(float, [render['x'], render['a'], render['w'], render['y']])\n",
        "        left_ = left + x\n",
        "        right_ = left_ + w\n",
        "        bottom_ = top + y\n",
        "        top_ = bottom_ - a\n",
        "\n",
        "        render_bbox.append((left_, top_, right_, bottom_))\n",
        "\n",
        "    return render_bbox\n",
        "\n",
        "def get_bbox(render_bbox):\n",
        "    min_x = min([x[0] for x in render_bbox])\n",
        "    min_y = min([x[1] for x in render_bbox])\n",
        "    max_x = max([x[2] for x in render_bbox])\n",
        "    max_y = max([x[3] for x in render_bbox])\n",
        "\n",
        "    return min_x, min_y, max_x, max_y\n",
        "\n",
        "def process_xml_dict(xml_dict, thumbnail):\n",
        "    processed_json = {}\n",
        "    processed_json['form'] = []\n",
        "\n",
        "    SHEET_SIZE = tuple(map(int, xml_dict['SHEET']['SHEETSIZE'].values()))\n",
        "    IM_SIZE = thumbnail.size\n",
        "\n",
        "    # Process XML to json\n",
        "    for i, text in enumerate(xml_dict['SHEET']['TEXT']):\n",
        "        left, top, right, bottom = map(float, text['Position'].values())\n",
        "        center = ((left + right) / 2, (top + bottom) / 2)\n",
        "\n",
        "        render_bbox = get_render_bbox(text)\n",
        "        if len(render_bbox) == 0: continue\n",
        "\n",
        "        XML_BBOX = get_bbox(render_bbox)\n",
        "\n",
        "        t = text['Text']\n",
        "        x1, y1, x2, y2 = process_bbox(XML_BBOX, IM_SIZE, SHEET_SIZE, int(text['@Rotate']), center)\n",
        "\n",
        "        processed_json['form'].append({\n",
        "            \"text\": t,\n",
        "            \"box\": [x1, y1, x2, y2],\n",
        "            \"font_id\": int(text['Font']['@FamilyIdx']),\n",
        "            \"font_size\": float(text['Font']['@Size']),\n",
        "            \"style\": {\n",
        "                \"bold\": text['Font']['Style']['@Bold'] == 'true',\n",
        "                \"italic\": text['Font']['Style']['@Italic'] == 'true',\n",
        "                \"strikeout\": text['Font']['Style']['@Strikeout'] == 'true',\n",
        "                \"underline\": text['Font']['Style']['@Underline'] == 'true'\n",
        "            },\n",
        "            \"linespace\": float(text['Font']['@LineSpace']),\n",
        "            \"opacity\": float(text['@Opacity']),\n",
        "            \"rotate\": float(text['@Rotate']),\n",
        "            \"id\": i,\n",
        "            \"sheet_size\" : SHEET_SIZE\n",
        "        })\n",
        "\n",
        "        processed_json['form'][-1]['words'] = []\n",
        "\n",
        "        render_pos = json.loads(text['RenderPos'])\n",
        "\n",
        "        for j, bbox in enumerate(render_bbox):\n",
        "            x1_, y1_, x2_, y2_ = process_bbox(bbox, IM_SIZE, SHEET_SIZE, int(text['@Rotate']), center)\n",
        "            color = render_pos['c'][j]['f']\n",
        "            color = color[4:-1]\n",
        "            color = list(map(int, color.split(\",\")))\n",
        "            processed_json['form'][-1]['words'].append({\n",
        "                \"text\": render_pos['c'][j]['t'],\n",
        "                \"box\": [x1_, y1_, x2_, y2_],\n",
        "                \"font_size\": float(render_pos['c'][j]['s']),\n",
        "                \"letter_spacing\": float(render_pos['c'][j]['ds']),\n",
        "                \"font_id\": int(render_pos['c'][j]['yd']),\n",
        "                \"color\": color\n",
        "            })\n",
        "\n",
        "    return processed_json\n",
        "\n",
        "def process_xml(sheet_url, thumbnail_url):\n",
        "    sample_thumbnail = Image.open(BytesIO(requests.get(thumbnail_url).content))\n",
        "    sample_xml = requests.get(sheet_url).content.decode(\"utf-8\")\n",
        "    sample_json = xml_to_dict.XMLtoDict().parse(sample_xml)\n",
        "\n",
        "    processed_json = process_xml_dict(sample_json, sample_thumbnail)\n",
        "\n",
        "    return processed_json\n",
        "\n",
        "def make_sample_json():\n",
        "    # Read sample CSV and download thumbnail, XML\n",
        "    df = pd.read_csv(xml_sample_loc)\n",
        "\n",
        "    for i in range(1600,len(df)):\n",
        "      if(i%100==0):\n",
        "        print(i)\n",
        "      sample_sheet = df.iloc[i]\n",
        "\n",
        "      try:\n",
        "        processed_json = process_xml(sample_sheet['sheet_url'], sample_sheet['thumbnail_url'])\n",
        "\n",
        "        filename = f\"data/processed_sample_{i}.json\"\n",
        "        with open(filename, \"w\") as file_:\n",
        "          json.dump(processed_json, file_, indent=4)\n",
        "      except:\n",
        "        print(f\"error occurred in df line {i}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK0ecmL5CTG-",
        "outputId": "bfbdacce-bf8d-4955-ee7c-19a7e266be1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1600\n",
            "1700\n",
            "1800\n",
            "error occurred in df line 1808\n",
            "error occurred in df line 1861\n",
            "1900\n",
            "error occurred in df line 1908\n",
            "error occurred in df line 1985\n",
            "2000\n",
            "error occurred in df line 2085\n",
            "2100\n",
            "2200\n",
            "error occurred in df line 2298\n",
            "2300\n",
            "error occurred in df line 2312\n",
            "error occurred in df line 2330\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "error occurred in df line 2615\n",
            "error occurred in df line 2659\n",
            "2700\n",
            "error occurred in df line 2719\n",
            "error occurred in df line 2771\n",
            "error occurred in df line 2777\n",
            "error occurred in df line 2778\n",
            "2800\n",
            "error occurred in df line 2836\n",
            "error occurred in df line 2837\n",
            "error occurred in df line 2838\n",
            "error occurred in df line 2839\n",
            "error occurred in df line 2840\n",
            "error occurred in df line 2841\n",
            "error occurred in df line 2842\n",
            "error occurred in df line 2843\n",
            "error occurred in df line 2844\n",
            "2900\n",
            "error occurred in df line 2903\n",
            "error occurred in df line 2906\n",
            "error occurred in df line 2950\n",
            "error occurred in df line 2962\n",
            "error occurred in df line 2980\n",
            "error occurred in df line 2987\n",
            "3000\n",
            "error occurred in df line 3042\n",
            "error occurred in df line 3056\n"
          ]
        }
      ],
      "source": [
        "make_sample_json() #약 30분 소요. xml파일을 json으로 변환"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3poxvfRhCXI5"
      },
      "source": [
        "##get text line in xml file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fw2PM9qCZNK",
        "outputId": "80a2e04b-33f6-422f-c4ff-f8dec7b52dff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "error in data/processed_sample_2060.json\n"
          ]
        }
      ],
      "source": [
        "#json파일에서 text들을 가져와 text_sum에 저장\n",
        "import json\n",
        "import os\n",
        "\n",
        "text_sum = []\n",
        "\n",
        "folder_path = \"data/\"  # 데이터 폴더 경로\n",
        "\n",
        "# 폴더 내의 파일 목록 가져오기\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "for file_name in file_list:\n",
        "    if file_name.endswith(\".json\"):  # .json 파일인 경우에만 처리\n",
        "        file_path = os.path.join(folder_path, file_name)  # 파일 경로 생성\n",
        "\n",
        "    try:\n",
        "      with open(file_path, \"r\") as file_:\n",
        "          data = json.load(file_)\n",
        "\n",
        "      for i in range(len(data['form'])):\n",
        "          if(data['form'][i]['text']!=None):\n",
        "            text_sum.append(data['form'][i]['text'])  # 요소 추가\n",
        "\n",
        "    except:\n",
        "      print(f\"error in {file_path}\")\n",
        "\n",
        "\n",
        "print(len(text_sum))\n",
        "print(text_sum[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "66ZWFovSCkOZ"
      },
      "source": [
        "##train custom tokenizer (based on ke-t5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuK8UyKICcRb"
      },
      "outputs": [],
      "source": [
        "train_tokenization_data = np.concatenate((text_sum,keyword_unique)) #text와 keyword 합쳐서 한번에 train\n",
        "\n",
        "print(len(train_tokenization_data))\n",
        "\n",
        "def get_training_corpus(): #개수가 많으므로 1000개씩 끊어서 return\n",
        "    return (\n",
        "        train_tokenization_data[i : i + 1000]\n",
        "        for i in range(0, len(train_tokenization_data), 1000)\n",
        "    )\n",
        "\n",
        "training_corpus = get_training_corpus()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2tiMdZ3CpMp"
      },
      "outputs": [],
      "source": [
        "old_tokenizer = AutoTokenizer.from_pretrained(\"KETI-AIR/ke-t5-base-ko\") #pre-trained된거 불러오기\n",
        "old_tokenizer.vocab_size #64100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc584Ff3CupF"
      },
      "outputs": [],
      "source": [
        "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 15000) #뒤 숫자는 우리 데이터에서 단어 개수\n",
        "tokenizer.vocab_size #14602\n",
        "tokenizer.save_pretrained(\"tokenizer_finetuned_ket5_by_xml_data\") #저장"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f5L7gXTnDM9K"
      },
      "source": [
        "##see tokenized result (추후 학습과 관련 x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmrA993oCycz"
      },
      "outputs": [],
      "source": [
        "#tokenized by finetuned-ke-t5\n",
        "#text_sum 안의 text들을 토큰화하여 text_token_list에 저장.\n",
        "\n",
        "text_token_list = np.array([],dtype=object)\n",
        "\n",
        "for idx , word in enumerate(train_tokenization_data):\n",
        "  input_word = word\n",
        "  try:\n",
        "    tokens = tokenizer.tokenize(input_word)\n",
        "    text_token_list = np.concatenate((text_token_list,tokens))\n",
        "  except:\n",
        "    print(f\"error occur in input_word {input_word}, idx = {idx}\")\n",
        "\n",
        "print(text_token_list[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zj2zkgtC1SE"
      },
      "outputs": [],
      "source": [
        "#keyword token과 text token들을 합쳐서 중복제거.\n",
        "\n",
        "token_list = np.concatenate((text_token_list,keyword_unique))\n",
        "\n",
        "token_list = list(set(token_list))\n",
        "\n",
        "print(len(token_list) ) #==14602\n",
        "\n",
        "print(token_list[:20])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TLTUiNUTDSsq"
      },
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LmJo1DsmEAev"
      },
      "source": [
        "##define custom tokenizer class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "R3v22ARiECUc"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5TokenizerFast, PreTrainedTokenizer, PreTrainedTokenizerBase\n",
        "\n",
        "import re\n",
        "import sentencepiece as spm\n",
        "\n",
        "# The special tokens of T5Tokenizer is hard-coded with <extra_id_{}>\n",
        "# Created another class UDOPTokenizer extending it to add special visual tokens like <loc_{}>, etc.\n",
        "\n",
        "#class UdopTokenizer(T5Tokenizer):\n",
        "class UdopTokenizer(AutoTokenizer):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_file,\n",
        "        eos_token=\"</s>\",\n",
        "        unk_token=\"<unk>\",\n",
        "        pad_token=\"<pad>\",\n",
        "        extra_ids=100,\n",
        "        loc_extra_ids=501,\n",
        "        other_extra_ids=200,\n",
        "        additional_special_tokens=[],\n",
        "        sp_model_kwargs=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        # Add extra_ids to the special token list\n",
        "        if extra_ids > 0 and not \"<extra_id_0>\" in additional_special_tokens:\n",
        "            additional_special_tokens = [\"<extra_id_{}>\".format(i) for i in range(extra_ids)]\n",
        "            additional_special_tokens.extend([\"<extra_l_id_{}>\".format(i) for i in range(extra_ids)])\n",
        "            additional_special_tokens.extend([\"</extra_l_id_{}>\".format(i) for i in range(extra_ids)])\n",
        "            additional_special_tokens.extend([\"<extra_t_id_{}>\".format(i) for i in range(extra_ids)])\n",
        "            additional_special_tokens.extend([\"</extra_t_id_{}>\".format(i) for i in range(extra_ids)])\n",
        "\n",
        "        if loc_extra_ids > 0 and not \"<loc_0>\" in additional_special_tokens:\n",
        "            additional_special_tokens.extend([\"<loc_{}>\".format(i) for i in range(loc_extra_ids)])\n",
        "\n",
        "        if other_extra_ids > 0 and not \"<other_0>\" in additional_special_tokens:\n",
        "            additional_special_tokens.extend([\"<other_{}>\".format(i) for i in range(other_extra_ids)])\n",
        "        print(additional_special_tokens)\n",
        "        PreTrainedTokenizer.__init__(\n",
        "            self,\n",
        "            eos_token=eos_token,\n",
        "            unk_token=unk_token,\n",
        "            pad_token=pad_token,\n",
        "            extra_ids=extra_ids,\n",
        "            additional_special_tokens=additional_special_tokens,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        self.sp_model_kwargs = {} if sp_model_kwargs is None else sp_model_kwargs\n",
        "\n",
        "        self.vocab_file = vocab_file\n",
        "        self._extra_ids = extra_ids\n",
        "        self._loc_extra_ids = loc_extra_ids\n",
        "        self._other_extra_ids = other_extra_ids\n",
        "\n",
        "        self.sp_model = spm.SentencePieceProcessor(**self.sp_model_kwargs)\n",
        "        self.sp_model.Load(vocab_file)\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return self.sp_model.get_piece_size() + self._extra_ids * 5 + self._loc_extra_ids + self._other_extra_ids\n",
        "\n",
        "    def get_vocab(self):\n",
        "        vocab = {self.convert_ids_to_tokens(\n",
        "            i): i for i in range(self.vocab_size)}\n",
        "        vocab.update(self.added_tokens_encoder)\n",
        "        return vocab\n",
        "\n",
        "    def _convert_token_to_id(self, token):\n",
        "        \"\"\" Converts a token (str) in an id using the vocab. \"\"\"\n",
        "        if token.startswith(\"<extra_id_\"):\n",
        "            match = re.match(r\"<extra_id_(\\d+)>\", token)\n",
        "            num = int(match.group(1))\n",
        "            return self.vocab_size - num - 1 - self._other_extra_ids - self._loc_extra_ids - self._extra_ids * 4\n",
        "        elif token.startswith(\"<extra_l_id_\"):\n",
        "            match = re.match(r\"<extra_l_id_(\\d+)>\", token)\n",
        "            num = int(match.group(1))\n",
        "            return self.vocab_size - num - 1 - self._other_extra_ids - self._loc_extra_ids - self._extra_ids * 3\n",
        "        elif token.startswith(\"</extra_l_id_\"):\n",
        "            match = re.match(r\"</extra_l_id_(\\d+)>\", token)\n",
        "            num = int(match.group(1))\n",
        "            return self.vocab_size - num - 1 - self._other_extra_ids - self._loc_extra_ids - self._extra_ids * 2\n",
        "        elif token.startswith(\"<extra_t_id_\"):\n",
        "            match = re.match(r\"<extra_t_id_(\\d+)>\", token)\n",
        "            num = int(match.group(1))\n",
        "            return self.vocab_size - num - 1 - self._other_extra_ids - self._loc_extra_ids - self._extra_ids\n",
        "        elif token.startswith(\"</extra_t_id_\"):\n",
        "            match = re.match(r\"</extra_t_id_(\\d+)>\", token)\n",
        "            num = int(match.group(1))\n",
        "            return self.vocab_size - num - 1 - self._other_extra_ids - self._loc_extra_ids\n",
        "        elif token.startswith(\"<loc_\"):\n",
        "            match = re.match(r\"<loc_(\\d+)>\", token)\n",
        "            num = int(match.group(1))\n",
        "            return self.vocab_size - num - 1 - self._other_extra_ids\n",
        "        elif token.startswith(\"<other_\"):\n",
        "            match = re.match(r\"<other_(\\d+)>\", token)\n",
        "            num = int(match.group(1))\n",
        "            return self.vocab_size - num - 1\n",
        "\n",
        "        return self.sp_model.piece_to_id(token)\n",
        "\n",
        "    def _convert_id_to_token(self, index):\n",
        "        \"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"\n",
        "        if index < self.sp_model.get_piece_size():\n",
        "            token = self.sp_model.IdToPiece(index)\n",
        "        else:\n",
        "\n",
        "            if index > self.sp_model.get_piece_size() + self._extra_ids * 5 + self._loc_extra_ids - 1:\n",
        "                index_loc = self.vocab_size - 1 - index\n",
        "                token = f\"<other_{index_loc}>\"\n",
        "            elif index > self.sp_model.get_piece_size() + self._extra_ids * 5 - 1:\n",
        "                index_loc = self.vocab_size - self._other_extra_ids - 1 - index\n",
        "                token = f\"<loc_{index_loc}>\"\n",
        "            elif index > self.sp_model.get_piece_size() + self._extra_ids * 4 - 1:\n",
        "                token = \"</extra_t_id_{}>\".format(self.vocab_size - self._other_extra_ids - self._loc_extra_ids - 1 - index)\n",
        "            elif index > self.sp_model.get_piece_size() + self._extra_ids * 3 - 1:\n",
        "                token = \"<extra_t_id_{}>\".format(self.vocab_size - self._other_extra_ids - self._loc_extra_ids - self._extra_ids - 1 - index)\n",
        "            elif index > self.sp_model.get_piece_size() + self._extra_ids * 2 - 1:\n",
        "                token = \"</extra_l_id_{}>\".format(self.vocab_size - self._other_extra_ids - self._loc_extra_ids - self._extra_ids * 2 - 1 - index)\n",
        "            elif index > self.sp_model.get_piece_size() + self._extra_ids - 1:\n",
        "                token = \"<extra_l_id_{}>\".format(self.vocab_size - self._other_extra_ids - self._loc_extra_ids - self._extra_ids * 3 - 1 - index)\n",
        "            elif index > self.sp_model.get_piece_size() - 1:\n",
        "                token = \"<extra_id_{}>\".format(self.vocab_size - self._other_extra_ids - self._loc_extra_ids - self._extra_ids * 4 - 1 - index)\n",
        "            else:\n",
        "                raise\n",
        "        return token"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r2IgTNFREGiV"
      },
      "source": [
        "##test tokenizer class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9kAEC08EFBE"
      },
      "outputs": [],
      "source": [
        "my_tokenizer = UdopTokenizer.from_pretrained(\"tokenizer_finetuned_ket5_by_xml_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mqDECyjoEJlK",
        "outputId": "0efb7dee-5661-40bf-cae8-c4b3d2d18405"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'참hereistory'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_tokenizer.vocab_size\n",
        "my_tokenizer.decode([4321,1231,1050])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1PuGSgsMGFl",
        "outputId": "81b89dfd-84bf-486c-d81f-8d0fbddf62c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['▁제목', ':', '▁할로윈', '▁파티', '▁참여', '자', '▁모집합니다', '!', '▁안녕', '하세요', '▁여러분', '!', '▁올해', '▁할로윈', '을', '▁기념', '하기', '▁위해', '▁우리', '는', '▁특별', '한', '▁할로윈', '▁파티', '를', '▁개', '최', '하려', '고', '▁합니다', '!', '▁파티', '는', '▁다양', '한', '▁활동', '과', '▁게임', ',', '▁맛있', '는', '▁음식', ',', '▁그리', '고', '▁', '엄', '청', '난', '▁재미', '로', '▁가득', '할', '▁예정', '입니다', '.', '▁이', '▁특별', '한', '▁이벤트', '에', '▁참여', '하', '실', '▁분들', '을', '▁모집', '하고', '자', '▁이', '▁글', '을', '▁올', '립니다', '.', '▁일', '시', ':', '▁10월', '▁3', '1일', '▁(', '토', '요일', ')', '▁', '오후', '▁7', '시', '부', '터', '▁장소', ':', '▁(', '장소', '▁명', '시', ')', '▁참', '가', '비', ':', '▁개인', '당', '▁10,000', '원', '▁할로윈', '▁파티', '에', '▁참여', '하시', '면', '▁아래', '와', '▁같은', '▁활동', '을', '▁즐', '길', '▁수', '▁있습니다', ':', '▁할로윈', '▁코스', '튬', '▁경', '연', '▁대회', ':', '▁여러분', '의', '▁창의력', '을', '▁발', '휘', '해', '▁가', '장', '▁멋진', '▁코스', '튬', '으로', '▁참', '가', '해', '보세요', '.', '▁최고', '의', '▁코스', '튬', '은', '▁상', '을', '▁받', '게', '▁됩니다', '!', '▁호', '러', '▁영화', '▁시청', ':', '▁공포', '와', '▁스', '릴', '을', '▁선', '사', '하는', '▁할로윈', '▁분위기', '의', '▁영화', '들', '을', '▁함께', '▁감', '상', '해', '보세요', '.', '▁', '트', '릭', '▁오', '어', '▁', '트', '릿', ':', '▁사', '탕', '과', '▁함께', '▁할로윈', '▁테마', '의', '▁', '트', '릭', '▁오', '어', '▁', '트', '릿', '▁게임', '을', '▁즐', '기', '며', '▁다', '른', '▁참', '가', '자들', '과', '▁즐거', '운', '▁시간을', '▁보내', '세요.', '▁유령', '▁이야기', '▁시간', ':', '▁무서운', '▁이야기', '를', '▁나', '누', '며', '▁유령', '의', '▁존재', '를', '▁느껴', '보세요', '.', '▁이', '▁파티', '는', '▁할로윈', '을', '▁축하', '하며', '▁친구들', '과', '▁함께', '▁재미', '있는', '▁시간을', '▁보내', '고', '▁싶은', '▁분들', '을', '▁위해', '▁준비', '되었', '습니다', '.', '▁모두', '가', '▁함께', '▁할로윈', '▁분위기', '를', '▁만들어', '나', '갈', '▁수', '▁있', '도', '록', '▁참여', '자', '▁여러분', '의', '▁', '활', '발', '한', '▁참여', '를', '▁기다', '립니다', '!', '▁참', '가', '▁신청', '은', '▁아래', '의', '▁연락처', '로', '▁신청', '해주', '시기', '▁바', '랍니다', ':', '▁이름', ':', '▁연락처', ':', '▁인', '원', '▁수', ':', '▁많', '은', '▁관심', '과', '▁참여', '▁부탁드립니다', '.', '▁함께', '▁무서운', '▁할로윈', '을', '▁즐', '기', '는', '▁파티', '에서', '▁만', '날', '▁수', '▁있', '기', '를', '▁기대', '합니다', '!', '▁감사합니다', '.', '▁[', '이름', ']', '▁[', '연', '락', '처', ']']\n",
            "[2612, 214, 6626, 7715, 2306, 505, 9373, 138, 8515, 2602, 5489, 138, 8361, 6626, 144, 2380, 758, 562, 1123, 181, 4012, 191, 6626, 7715, 185, 891, 13958, 7656, 353, 3309, 138, 7715, 181, 1526, 191, 1514, 309, 5258, 113, 10191, 181, 4232, 113, 4951, 353, 103, 3297, 2996, 2483, 4656, 300, 9259, 501, 5801, 304, 105, 382, 4012, 191, 2464, 212, 2306, 1518, 441, 3289, 144, 1727, 498, 505, 382, 4432, 144, 7463, 11818, 105, 751, 345, 214, 4759, 198, 2269, 219, 2225, 6117, 173, 103, 9452, 447, 345, 615, 523, 1730, 214, 219, 11086, 2737, 345, 173, 4321, 262, 715, 214, 1740, 2749, 3590, 614, 6626, 7715, 212, 2306, 5338, 580, 6757, 335, 3642, 1514, 144, 4872, 1330, 332, 756, 214, 6626, 6372, 2, 2268, 2473, 7936, 214, 5489, 168, 4555, 144, 1864, 6211, 389, 489, 347, 3928, 6372, 2, 311, 4321, 262, 389, 4819, 105, 3091, 168, 6372, 2, 200, 1014, 144, 2651, 461, 4487, 138, 3339, 1055, 4987, 9760, 214, 9052, 335, 2432, 6512, 144, 1585, 433, 349, 6626, 2547, 168, 4987, 650, 144, 983, 3566, 874, 389, 4819, 105, 103, 559, 6476, 1075, 495, 103, 559, 3059, 214, 1355, 6470, 309, 983, 6626, 8928, 168, 103, 559, 6476, 1075, 495, 103, 559, 3059, 5258, 144, 4872, 248, 1346, 895, 2102, 4321, 262, 7732, 309, 6713, 520, 7371, 9219, 1160, 9861, 3634, 1950, 214, 8651, 3634, 185, 677, 6112, 1346, 9861, 168, 6009, 185, 8432, 4819, 105, 382, 7715, 181, 6626, 144, 10167, 1776, 3496, 309, 983, 4656, 2234, 7371, 9219, 353, 3172, 3289, 144, 562, 1904, 5068, 924, 105, 3507, 262, 983, 6626, 2547, 185, 4068, 610, 3704, 332, 1775, 302, 1173, 2306, 505, 5489, 168, 103, 3575, 2475, 191, 2306, 185, 7035, 11818, 138, 4321, 262, 1147, 200, 6757, 168, 4615, 300, 1147, 10891, 3194, 1187, 3444, 214, 5303, 214, 4615, 214, 1249, 614, 332, 214, 1405, 200, 2113, 309, 2306, 4189, 105, 983, 8651, 6626, 144, 4872, 248, 181, 7715, 434, 2093, 1450, 332, 1775, 248, 185, 9445, 317, 138, 7321, 105, 683, 3201, 585, 683, 2473, 1947, 2107, 585]\n",
            "제목: 할로윈 파티 참여자 모집합니다! 안녕하세요 여러분! 올해 할로윈을 기념하기 위해 우리는 특별한 할로윈 파티를 개최하려고 합니다! 파티는 다양한 활동과 게임, 맛있는 음식, 그리고 엄청난 재미로 가득할 예정입니다. 이 특별한 이벤트에 참여하실 분들을 모집하고자 이 글을 올립니다. 일시: 10월 31일 (토요일) 오후 7시부터 장소: (장소 명시) 참가비: 개인당 10,000원 할로윈 파티에 참여하시면 아래와 같은 활동을 즐길 수 있습니다: 할로윈 코스<unk> 경연 대회: 여러분의 창의력을 발휘해 가장 멋진 코스<unk>으로 참가해보세요. 최고의 코스<unk>은 상을 받게 됩니다! 호러 영화 시청: 공포와 스릴을 선사하는 할로윈 분위기의 영화들을 함께 감상해보세요. 트릭 오어 트릿: 사탕과 함께 할로윈 테마의 트릭 오어 트릿 게임을 즐기며 다른 참가자들과 즐거운 시간을 보내세요. 유령 이야기 시간: 무서운 이야기를 나누며 유령의 존재를 느껴보세요. 이 파티는 할로윈을 축하하며 친구들과 함께 재미있는 시간을 보내고 싶은 분들을 위해 준비되었습니다. 모두가 함께 할로윈 분위기를 만들어나갈 수 있도록 참여자 여러분의 활발한 참여를 기다립니다! 참가 신청은 아래의 연락처로 신청해주시기 바랍니다: 이름: 연락처: 인원 수: 많은 관심과 참여 부탁드립니다. 함께 무서운 할로윈을 즐기는 파티에서 만날 수 있기를 기대합니다! 감사합니다. [이름] [연락처]\n"
          ]
        }
      ],
      "source": [
        "user_text = '''제목: 할로윈 파티 참여자 모집합니다!\n",
        "\n",
        "안녕하세요 여러분!\n",
        "\n",
        "올해 할로윈을 기념하기 위해 우리는 특별한 할로윈 파티를 개최하려고 합니다! 파티는 다양한 활동과 게임, 맛있는 음식, 그리고 엄청난 재미로 가득할 예정입니다. 이 특별한 이벤트에 참여하실 분들을 모집하고자 이 글을 올립니다.\n",
        "\n",
        "일시: 10월 31일 (토요일) 오후 7시부터\n",
        "장소: (장소 명시)\n",
        "참가비: 개인당 10,000원\n",
        "\n",
        "할로윈 파티에 참여하시면 아래와 같은 활동을 즐길 수 있습니다:\n",
        "\n",
        "할로윈 코스튬 경연 대회: 여러분의 창의력을 발휘해 가장 멋진 코스튬으로 참가해보세요. 최고의 코스튬은 상을 받게 됩니다!\n",
        "호러 영화 시청: 공포와 스릴을 선사하는 할로윈 분위기의 영화들을 함께 감상해보세요.\n",
        "트릭 오어 트릿: 사탕과 함께 할로윈 테마의 트릭 오어 트릿 게임을 즐기며 다른 참가자들과 즐거운 시간을 보내세요.\n",
        "유령 이야기 시간: 무서운 이야기를 나누며 유령의 존재를 느껴보세요.\n",
        "\n",
        "이 파티는 할로윈을 축하하며 친구들과 함께 재미있는 시간을 보내고 싶은 분들을 위해 준비되었습니다. 모두가 함께 할로윈 분위기를 만들어나갈 수 있도록 참여자 여러분의 활발한 참여를 기다립니다!\n",
        "\n",
        "참가 신청은 아래의 연락처로 신청해주시기 바랍니다:\n",
        "\n",
        "이름:\n",
        "연락처:\n",
        "인원 수:\n",
        "\n",
        "많은 관심과 참여 부탁드립니다. 함께 무서운 할로윈을 즐기는 파티에서 만날 수 있기를 기대합니다!\n",
        "\n",
        "감사합니다.\n",
        "\n",
        "[이름] [연락처]'''\n",
        "\n",
        "tokens = my_tokenizer.tokenize(user_text)\n",
        "\n",
        "print(tokens)\n",
        "\n",
        "ids = my_tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(ids)\n",
        "\n",
        "decoded = my_tokenizer.decode(ids)\n",
        "\n",
        "print(decoded)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MuEpv5Nlh5T2"
      },
      "source": [
        "#define data collactor (2023.06.23 revised)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fMEq4ONo6qKx"
      },
      "source": [
        "##잡다한 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qp_APhcjuJwB"
      },
      "outputs": [],
      "source": [
        "########################## this block is for testing ############################\n",
        "import json\n",
        "import os\n",
        "\n",
        "folder_path = \"data/\"  # 데이터 폴더 경로\n",
        "\n",
        "# 폴더 내의 파일 목록 가져오기\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "file_name = file_list[14]\n",
        "\n",
        "print(file_name)\n",
        "\n",
        "if file_name.endswith(\".json\"):  # .json 파일인 경우에만 처리\n",
        "  file_path = os.path.join(folder_path, file_name)  # 파일 경로 생성\n",
        "\n",
        "  with open(file_path, \"r\") as file_:\n",
        "    data = json.load(file_)\n",
        "\n",
        "  print(data)\n",
        "  print()\n",
        "  print(data['form'])\n",
        "  print(len(data['form']))\n",
        "\n",
        "  for i in range(len(data['form'])):\n",
        "    if(data['form'][i]['text']!=None):\n",
        "      print(data['form'][i]['text'])\n",
        "      print(data['form'][i]['box'])\n",
        "      print(data['form'][i]['words']) #우선은 단어별이 아닌 문장별로 진행\n",
        "      print()\n",
        "\n",
        "  for form in data['form']:\n",
        "    for word in form['words']:\n",
        "      print(word)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5S3ZNoZQ6zNl"
      },
      "source": [
        "## 기본 util 함수들 (UDOP github 복붙내용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NYgrnNhAsQj7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "    codes for just preprocessing\n",
        "\"\"\"\n",
        "\n",
        "def normalText(t):\n",
        "    if type(t) is float:\n",
        "        if t == int(t):\n",
        "            t = int(t)\n",
        "    t = str(t)\n",
        "    return t.strip()\n",
        "\n",
        "\n",
        "def get_prop(node, name):\n",
        "    title = node.get(\"title\")\n",
        "    props = title.split(\";\")\n",
        "    for prop in props:\n",
        "        (key, args) = prop.split(None, 1)\n",
        "        args = args.strip('\"')\n",
        "        if key == name:\n",
        "            return args\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_bb(bb):\n",
        "    bbs = [float(j) for j in bb]\n",
        "    xs, ys = [], []\n",
        "    for i, b in enumerate(bbs):\n",
        "        if i % 2 == 0:\n",
        "            xs.append(b)\n",
        "        else:\n",
        "            ys.append(b)\n",
        "    return [min(xs), min(ys), max(xs), max(ys)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4OSf93pnzxho"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms import functional as F\n",
        "\n",
        "\"\"\"\n",
        "    codes for just preprocessing image data\n",
        "\"\"\"\n",
        "def get_visual_bbox(image_size=224):\n",
        "    image_feature_pool_shape = [image_size//16, image_size//16]\n",
        "    visual_bbox_x = (torch.arange(\n",
        "        0,\n",
        "        1.0 * (image_feature_pool_shape[1] + 1),\n",
        "        1.0,\n",
        "    ) / image_feature_pool_shape[1])\n",
        "    visual_bbox_y = (torch.arange(\n",
        "        0,\n",
        "        1.0 * (image_feature_pool_shape[0] + 1),\n",
        "        1.0,\n",
        "    ) / image_feature_pool_shape[0])\n",
        "    visual_bbox_input = torch.stack(\n",
        "        [\n",
        "            visual_bbox_x[:-1].repeat(\n",
        "                image_feature_pool_shape[0], 1),\n",
        "            visual_bbox_y[:-1].repeat(\n",
        "                image_feature_pool_shape[1], 1).transpose(\n",
        "                    0, 1),\n",
        "            visual_bbox_x[1:].repeat(\n",
        "                image_feature_pool_shape[0], 1),\n",
        "            visual_bbox_y[1:].repeat(\n",
        "                image_feature_pool_shape[1], 1).transpose(\n",
        "                    0, 1),\n",
        "        ],\n",
        "        dim=-1,\n",
        "    ).view(-1, 4)\n",
        "    return visual_bbox_input\n",
        "\n",
        "class Normalize(object):\n",
        "    def __init__(self, mean, std, format='rgb'):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.format = format.lower()\n",
        "\n",
        "    def __call__(self, image):\n",
        "        if 'bgr' in self.format:\n",
        "            image = image[[2, 1, 0]]\n",
        "        if '255' in self.format:\n",
        "            image = image * 255\n",
        "        if image.size(0) == 1:\n",
        "            image = image.repeat(3, 1, 1)\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image\n",
        "\n",
        "def img_trans_torchvision(image, image_size=224):\n",
        "    trans = T.Compose([\n",
        "            T.Resize([image_size,image_size]),\n",
        "            T.ToTensor(),\n",
        "            Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )])\n",
        "\n",
        "    image = trans(image)  # copy to make it writeable\n",
        "    return image"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EhwgfrlO64pu"
      },
      "source": [
        "##data collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LpmQ2hRXh82I"
      },
      "outputs": [],
      "source": [
        "class DataCollatorForT5DocCLS:\n",
        "    \"\"\"\n",
        "    Data collator used for T5 document classification\n",
        "    \"\"\"\n",
        "    def __init__(self, tokenizer=None, meta_path=None, input_length=None, target_length=None, pad_token_id=None, decoder_start_token_id=None):\n",
        "\n",
        "        self.tokenizer = tokenizer #이전에 만든 udop tokenizer를 불러옴\n",
        "        self.input_length = input_length\n",
        "        self.target_length = target_length\n",
        "        self.pad_token_id = pad_token_id\n",
        "        self.decoder_start_token_id = decoder_start_token_id\n",
        "\n",
        "    def __call__(self, user_prompt ,ori_input_ids, ori_bbox_list, labels=None):\n",
        "\n",
        "        # \"원래 input text 정보 & bounding box\"\n",
        "        # -->\n",
        "        # \"prompt text 정보 + 원래 input text 정보\" list\n",
        "        # +\n",
        "        # [0,0,0,0]을 promt text token 개수만큼 + 원래 bounding box\n",
        "\n",
        "        #prompt_text = 'document classification.'\n",
        "        prompt_text = user_prompt\n",
        "        prompt_ids =  self.tokenizer.encode(prompt_text, add_special_tokens=False)\n",
        "        input_ids = prompt_ids + ori_input_ids\n",
        "        bbox_list = [[0,0,0,0]] * len(prompt_ids) + ori_bbox_list\n",
        "\n",
        "        if(labels!=None):  #label은 classification에서만 수행\n",
        "        #인줄 알았는데 layout modeling 이런것도 다 output이 있으니까 label==output 인건가..???\n",
        "          labels = self.tokenizer.encode(labels, add_special_tokens=True)\n",
        "\n",
        "        return input_ids, labels, bbox_list"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ENujqg_z68np"
      },
      "source": [
        "##dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BKcHFAituZb"
      },
      "outputs": [],
      "source": [
        "# 해당 부분은 json파일의 문장을 line-by-line으로 읽는 것으로 해당 함수 수정 완료.\n",
        "def read_ocr_core_engine(file, image_dir, tokenizer, max_seq_length=None, num_img_embeds=None, image_size=224):\n",
        "    #max_seq_length와 num_img_embeds 는 원본 코드에서도 안쓰는데 왜있는거지?\n",
        "\n",
        "    with open(file, 'r', encoding='utf8') as f:\n",
        "        try:\n",
        "            data = json.load(f)\n",
        "        except:\n",
        "            data = {}\n",
        "    rets = []\n",
        "    n_split = 0\n",
        "\n",
        "    page_size = data['form'][0]['sheet_size'] #(1280,720)\n",
        "    #page_size = (width, height) 추후 해당 내용 json파일 추가 필요\n",
        "    tiff_images = Image.open(image_dir)\n",
        "    image = img_trans_torchvision(tiff_images, image_size)\n",
        "\n",
        "    text_list, bbox_list = [], []\n",
        "    for form in data['form']: #문장별로 쪼갬\n",
        "      for word in form['words']: #단어별로 쪼갬\n",
        "\n",
        "        if word == ' ': #띄어쓰기는 건너뛰기\n",
        "          continue\n",
        "\n",
        "        sub_tokens = tokenizer.tokenize(word['text']) #단어별로 쪼갠걸 다시 토큰화 (하나의 단어도 여러개의 토큰 가능)\n",
        "        for sub_token in sub_tokens:\n",
        "          text_list.append(sub_token)\n",
        "          bbox_list.append(word['box']) #현재는 단어별 bbox, 추후 문장별 bbox로도 수정 가능\n",
        "          #bbox_list.append(form['box'])\n",
        "\n",
        "    if len(text_list) > 0:\n",
        "      rets.append([text_list, bbox_list, image, page_size])\n",
        "\n",
        "    assert len(text_list) == len(bbox_list)\n",
        "    n_split = len(rets)\n",
        "\n",
        "    return rets, n_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXgUVgtL2svj"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "EMPTY_BOX = [0, 0, 0, 0]\n",
        "SEP_BOX = [1000, 1000, 1000, 1000]\n",
        "\n",
        "class RvlCdipDataset(Dataset):\n",
        "\n",
        "    #NUM_LABELS = 16\n",
        "\n",
        "    def __init__(self , tokenizer , data_args , mode='train'):\n",
        "\n",
        "        \"\"\" Structure of data directory:\n",
        "\n",
        "            --- xml_sample_loc (.csv)\n",
        "                   ├── images_url\n",
        "                   └── labels_url\n",
        "            --- data (folder)\n",
        "                   └── processed_sample{index} .json\n",
        "        \"\"\"\n",
        "        self.main_df = pd.read_csv(xml_sample_loc) # xml_sample.csv 파일 저장\n",
        "\n",
        "        self.sheet_url = 'sheet_url'\n",
        "        self.image_url = 'thumbnail_url'\n",
        "\n",
        "        if mode == 'train': #train ,val, test 에 따라 사용하는 data의 범위가 다름. (근데 self-supervised도 이거 필요 있나..? )\n",
        "            file_data_range = ( 0 , int(len(self.main_df) * 0.6 ) )\n",
        "        elif mode == 'val':\n",
        "            file_data_range = ( int(len(self.main_df) * 0.6 ) , int(len(self.main_df) * 0.8 ) )\n",
        "        elif mode == 'test':\n",
        "            file_data_range = ( int(len(self.main_df) * 0.8 ) , int(len(self.main_df) ) )\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        self.cls_bbox = EMPTY_BOX[:]\n",
        "        self.pad_bbox = EMPTY_BOX[:]\n",
        "        self.sep_bbox = SEP_BOX[:]\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = data_args.max_seq_length\n",
        "        self.num_img_embeds = 0\n",
        "\n",
        "        label_list = None #get_rvlcdip_labels() #classification task에서만 사용하는 변수\n",
        "        self.label_list = label_list\n",
        "        self.label_map = dict(zip(list(range(len(self.label_list))), self.label_list))\n",
        "        self.n_classes = len(label_list)\n",
        "        self.label_list = label_list\n",
        "\n",
        "        self.image_size = data_args.image_size\n",
        "\n",
        "        self.examples = []\n",
        "        self.labels = []\n",
        "        self.images = []\n",
        "\n",
        "        self.cls_collator = DataCollatorForT5DocCLS( #기존에 정의한 토크나이저 선언\n",
        "                tokenizer=tokenizer,\n",
        "            )\n",
        "\n",
        "\n",
        "        results = [self.load_file(file_idx) for file_idx in tqdm(range(file_data_range[0],file_data_range[1]))]\n",
        "        for labels, examples, images in results:\n",
        "            self.labels += labels\n",
        "            self.examples += examples\n",
        "            self.images += images\n",
        "        assert len(self.labels) == len(self.examples)\n",
        "\n",
        "    def load_file(self, file_idx):\n",
        "        labels, examples, images = [], [], []\n",
        "\n",
        "        labels.append(0) ############### label 미정으로 일단 다 0 ##########\n",
        "        examples.append(f\"data/processed_sample{file_idx} .json\")\n",
        "        images.append(self.main_df[file_idx][self.image_url])\n",
        "\n",
        "        return labels, examples, images\n",
        "\n",
        "    def __getitem__(self, index): #완료\n",
        "        try:\n",
        "            label = self.labels[index]\n",
        "            label = self.label_map[int(label)]\n",
        "\n",
        "            rets, n_split = read_ocr_core_engine(self.examples[index], self.images[index] , self.tokenizer, self.max_seq_length, self.num_img_embeds, self.image_size)\n",
        "\n",
        "            if n_split == 0:\n",
        "                # Something wrong with the .ocr.json file\n",
        "                print(f\"EMPTY ENTRY in index {index}\")\n",
        "                return self[(index + 1) % len(self)]\n",
        "            for i in range(n_split): #정상적으로 코드 실행됬다면 n_split==1 임.\n",
        "                text_list, bbox_list, image, page_size = rets[i]\n",
        "                (width, height) = page_size\n",
        "                bbox = [  #이미지 크기에 맞게 정규화\n",
        "                    [\n",
        "                        b[0] / width,\n",
        "                        b[1] / height,\n",
        "                        b[2] / width,\n",
        "                        b[3] / height,\n",
        "                    ]\n",
        "                    for b in bbox_list\n",
        "                ]\n",
        "\n",
        "                visual_bbox_input = get_visual_bbox(self.image_size) # (x_min, y_min, x_max, y_max) 형태의 좌표로 이루어진 텐서 반환\n",
        "\n",
        "                input_ids = self.tokenizer.convert_tokens_to_ids(text_list) #토큰 자른것들을 token id들로 변환\n",
        "\n",
        "                input_ids, labels, bbox_input = self.cls_collator(\"user prompt\", input_ids, bbox, label) #prompt 붙여서 최종 input,bbox,label을 만듦. ################################\n",
        "                attention_mask = [1] * len(input_ids)\n",
        "                decoder_attention_mask = [1] * len(labels)\n",
        "\n",
        "                char_list = [0]\n",
        "                char_bbox_list = [[0,0,0,0]]\n",
        "                char_ids = torch.tensor(char_list, dtype=torch.long)\n",
        "                char_bbox_input = torch.tensor(char_bbox_list, dtype=torch.float)\n",
        "\n",
        "                bbox_input = torch.tensor(bbox_input, dtype=torch.float)\n",
        "                labels = torch.tensor(labels, dtype=torch.long)\n",
        "                input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
        "                attention_mask = torch.tensor(attention_mask, dtype=torch.long)\n",
        "                decoder_attention_mask = torch.tensor(decoder_attention_mask, dtype=torch.long)\n",
        "                assert len(bbox_input) == len(input_ids)\n",
        "                assert len(bbox_input.size()) == 2\n",
        "                assert len(char_bbox_input.size()) == 2\n",
        "\n",
        "                return_dict =  {\n",
        "                    \"input_ids\": input_ids,\n",
        "                    \"attention_mask\": attention_mask,\n",
        "                    \"labels\": labels,\n",
        "                    \"seg_data\": bbox_input,\n",
        "                    \"visual_seg_data\": visual_bbox_input,\n",
        "                    \"decoder_attention_mask\": decoder_attention_mask,\n",
        "                    \"image\": image,\n",
        "                    'char_ids': char_ids,\n",
        "                    'char_seg_data': char_bbox_input\n",
        "                }\n",
        "                assert input_ids is not None\n",
        "\n",
        "                return return_dict\n",
        "        except:\n",
        "            return self[(index + 1) % len(self)]\n",
        "\n",
        "    #def get_labels(self): # classification에서 label의 종류 출력하는 함수. 우리는 필요 없을 듯.\n",
        "    #    return list(map(str, list(range(self.NUM_LABELS))))\n",
        "\n",
        "    def pad_tokens(self, input_ids, bbox): #이건 그냥 길이 max_len에 맞게 맞추는 함수\n",
        "        # [CLS], sentence, [SEP]\n",
        "        tokenized_tokens = self.tokenizer.build_inputs_with_special_tokens(input_ids)\n",
        "        start_token, _, end_token = tokenized_tokens[0], tokenized_tokens[1:-1], tokenized_tokens[-1]\n",
        "\n",
        "        sentence = tokenized_tokens\n",
        "        expected_seq_length = self.max_seq_length - self.num_img_embeds\n",
        "        mask = torch.zeros(expected_seq_length)\n",
        "        mask[:len(sentence)] = 1\n",
        "\n",
        "        bbox = [self.cls_bbox] + bbox + [self.sep_bbox]\n",
        "        while len(sentence) < expected_seq_length:\n",
        "            sentence.append(self.tokenizer.pad_token_id)\n",
        "            bbox.append(self.pad_bbox)\n",
        "\n",
        "        assert len(sentence) == len(bbox)\n",
        "        return (sentence, mask, bbox, start_token, end_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD8aQLANh_qF"
      },
      "outputs": [],
      "source": [
        "temp = DataCollatorForT5DocCLS(tokenizer = my_tokenizer)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zzxQlolUvU4E"
      },
      "source": [
        "#labeling testing(demo) (2023.06.23. revised)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lw0f6QNV7wKy"
      },
      "source": [
        "## 그냥 github 코드 돌려본 내용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJQGK33tvXEn",
        "outputId": "bef7ad55-fb01-4777-c096-e4baf03228d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input sample number : 2\n",
            "Number of Sentence : 3\n",
            "WORSHIP FROM HOME\n",
            "ONLINE WORSHIP\n",
            "See, I will create new heavens and a new earth.\n",
            " The former things will not be remembered, nor will they come to mind (Isaiah 65:17)\n",
            "Targeted Sentence : See, I will create new heavens and a new earth.\n",
            " The former things will not be remembered, nor will they come to mind (Isaiah 65:17)\n",
            "\n",
            "Prompt : \"Layout Modeling. WORSHIP FROM HOME ONLINE WORSHIP <extra_l_id_0> See, I will create new heavens and a new earth.\n",
            " The former things will not be remembered, nor will they come to mind (Isaiah 65:17) </extra_l_id_0>\"\n",
            "\n",
            "Label : <extra_l_id_0> <loc_77> <loc_179> <loc_234> <loc_219>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Randomized Labeling Test for Layout Modeling (sentence version)\n",
        "\n",
        "# 원래는 좀 더 세세하게 word 단위로 라벨링하려 했는데, 레이아웃에 중점을 두면\n",
        "# 문장 단위로 라벨링하는 게 나을 것 같아서 문장 단위로 했습니다\n",
        "\n",
        "# 완성된 Prompt는 Tokenizer에 넣어질 예정\n",
        "# 이 코드 참고해서 Dataset 클래스에 Labeling 코드 추가하면 될 듯!\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Select sample num\n",
        "idx = input('Input sample number : ')\n",
        "\n",
        "test_path = f'./data/processed_sample_{idx}.json'\n",
        "\n",
        "# Load json\n",
        "with open(test_path, 'r', encoding='utf8') as f:\n",
        "    try:\n",
        "        data = json.load(f)\n",
        "    except:\n",
        "        data = {}\n",
        "\n",
        "print(f'Number of Sentence : {len(data[\"form\"])}')\n",
        "\n",
        "for sentence in data['form']:\n",
        "    print(sentence['text'])\n",
        "\n",
        "# Randomly pick sentence to label\n",
        "target_sentence_idx = random.randint(0, len(data['form'])-1)\n",
        "\n",
        "print(f'Targeted Sentence : {data[\"form\"][target_sentence_idx][\"text\"]}')\n",
        "\n",
        "target_sentence = data['form'][target_sentence_idx]\n",
        "\n",
        "label = ''\n",
        "\n",
        "for i in range(len(target_sentence['box'])):\n",
        "    n = target_sentence['box'][i]\n",
        "    # Layout Normalization\n",
        "    if i % 2 == 0:\n",
        "        label += f'<loc_{int(n*500/1280)}> '\n",
        "    else:\n",
        "        label += f'<loc_{int(n*500/720)}> '\n",
        "\n",
        "label = '<extra_l_id_0> ' + label[:-1]\n",
        "prompt = 'Layout Modeling.'\n",
        "\n",
        "for i in range(len(data['form'])):\n",
        "    if i == target_sentence_idx:\n",
        "        # UDOP 논문 5페이지 참조. 얘네가 Layout Modeling 할 때 sentinel token을\n",
        "        # <layout_0>으로 했는데, UdopTokenizer에는 그런 token이 없어서 일단 <extra_l_id_0>으로 대체했음!\n",
        "        # Layout Modeling => <extra_l_id_0>\n",
        "        # Visual Text Recognition => <extra_t_id_0>\n",
        "        # Joint Text_Layout Reconstruction => <extra_id_0>\n",
        "        prompt += ' <extra_l_id_0> ' + data['form'][i]['text'] + ' </extra_l_id_0>'\n",
        "    else:\n",
        "        prompt += ' ' + data['form'][i]['text']\n",
        "\n",
        "print(f'\\nPrompt : \"{prompt}\"\\n')\n",
        "\n",
        "print(f'Label : {label}\\n')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PLzhr1Hd72Bq"
      },
      "source": [
        "## data collactor 구현 시도"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UzJSvVf75Xe"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "                Classification DataSet에서는 다음과 같은 param들을 return함.\n",
        "\n",
        "                return_dict =  {\n",
        "                    \"input_ids\": input_ids,                           ## prompt까지 추가된 layout + text 정보들을 tokenization 한 것.\n",
        "                    \"attention_mask\": attention_mask,                 ##\n",
        "                    \"labels\": labels,                                 ## 모델이 맞추어야 하는 값을 tokenization 한 것.\n",
        "                    \"seg_data\": bbox_input,                           ## bounding box [[12,24,42,42],[24,53,64,12] ... ] 정보들 저장\n",
        "                    \"visual_seg_data\": visual_bbox_input,             ## image patch 별 min x , min y, max x, max y 를 저장\n",
        "                    \"decoder_attention_mask\": decoder_attention_mask, ##\n",
        "                    \"image\": image, ## 이미지 tensor로 변환한 것.     ##\n",
        "                    'char_ids': char_ids,                             ##\n",
        "                    'char_seg_data': char_bbox_input                  ##\n",
        "                }\n",
        "\n",
        "                DataCollator에서 해당 변수에 없는 내용들을 사용한다\n",
        "                -->\n",
        "                다른 Dataset (ex. layout, joint-text Dataset)에서 해당 변수들을 사용하였다.\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "              DataCollactor를 통과한 Batch는 다음과 같은 변수들을 가지고 있어야 함.\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,                                              ## okay\n",
        "        attention_mask=None,                                         ## okay\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        head_mask=None,\n",
        "        past_key_values=None,\n",
        "        ids_keep=None,                                               ## okay\n",
        "        use_cache=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "        cross_attn_head_mask = None,\n",
        "        position_bias=None,  # modified line,\n",
        "        inputs_patches=None, # modified line,\n",
        "        seg_data=None, # modified line,\n",
        "        visual_seg_data=None, # modified line,\n",
        "        num_patches=None, # modified line,\n",
        "        special_vis_token=None, # modified line,\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        " encoder_outputs = self.encoder(\n",
        "                input_ids=input_ids #ok\n",
        "                seg_data=seg_data,  #ok\n",
        "                visual_seg_data=visual_seg_data, #ok\n",
        "                inputs_patches=inputs_patches,\n",
        "                num_patches=num_patches,\n",
        "                special_vis_token=self.special_vis_token,\n",
        "                ids_keep=ids_keep,\n",
        "                attention_mask=attention_mask, #ok\n",
        "                inputs_embeds=inputs_embeds,\n",
        "                head_mask=head_mask,\n",
        "                output_attentions=output_attentions,\n",
        "                output_hidden_states=output_hidden_states,\n",
        "                return_dict=return_dict,\n",
        "            )\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "@dataclass\n",
        "class DataCollator:\n",
        "    tokenizer: Union[PreTrainedTokenizer, PreTrainedTokenizerFast] = None #얘 안쓰는데 왜있지\n",
        "    padding: Union[bool, str, PaddingStrategy] = True #얘 안쓰는데 왜있지 2\n",
        "    max_length: Optional[int] = 1024\n",
        "    max_length_decoder: Optional[int] = 512\n",
        "    max_length_char: Optional[int] = 1024+512\n",
        "    pad_to_multiple_of: Optional[int] = None # 얘 안쓰는데 왜있지 3\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]):# -> Dict[str, torch.Tensor]:\n",
        "        if features[0] is None:\n",
        "            return {'placeholder': torch.zeros(size=(2, 2), dtype=torch.long)}\n",
        "        batch_size = len(features)\n",
        "        special_labels = ['text_image_match_labels', 'image', 'class', 'image_mask_label', 'ids_restore', 'ids_keep']\n",
        "        max_len = self.max_length\n",
        "        max_len_decoder = self.max_length_decoder\n",
        "        max_len_char = self.max_length_char\n",
        "        max_feature_len = max([f[\"input_ids\"].shape[0] for f in features])\n",
        "        max_feature_len_decoder = max([f[\"labels\"].shape[0] for f in features])\n",
        "\n",
        "        target_len = min(max_feature_len, max_len)\n",
        "        target_len_decoder = min(max_feature_len_decoder, max_len_decoder)\n",
        "        # if features[0][\"char_ids\"] is not None:\n",
        "        if \"char_ids\" in features[0]:\n",
        "            max_feature_len_char = max([f[\"char_ids\"].shape[0] for f in features])\n",
        "            target_len_char = min(max_feature_len_char, max_len_char)\n",
        "\n",
        "        batch = {}\n",
        "        for key in features[0].keys():\n",
        "            pad_value = 0\n",
        "            if key in [\"seg_data\", \"decoder_seg_data\", \"char_seg_data\"]:\n",
        "                pad_value = [0] * 4\n",
        "            elif key in ['labels', 'image_mask_labels']:\n",
        "                pad_value = -100\n",
        "            elif key in special_labels:\n",
        "                continue\n",
        "\n",
        "            if key in ['decoder_input_ids', 'labels', 'decoder_attention_mask', 'decoder_seg_data']:\n",
        "                batched_feature = torch.stack([pad_sequence_native(f[key], target_len_decoder, pad_value) for f in features], dim=0)\n",
        "            elif key == \"visual_seg_data\":\n",
        "                batched_feature = torch.stack([f[key] for f in features], dim=0)\n",
        "            elif key in ['char_ids', 'char_seg_data']:\n",
        "                batched_feature = torch.stack([pad_sequence_native(f[key], target_len_char, pad_value) for f in features], dim=0)\n",
        "            else:\n",
        "                batched_feature = torch.stack([pad_sequence_native(f[key], target_len, pad_value) for f in features], dim=0)\n",
        "            batch[key] = batched_feature\n",
        "\n",
        "        if \"position_ids\" not in batch:\n",
        "            position_ids = torch.stack([torch.arange(target_len, dtype=torch.long) for _ in range(batch_size)])\n",
        "            batch[\"position_ids\"] = position_ids\n",
        "\n",
        "\n",
        "        if 'image' in features[0]:\n",
        "            image_list = torch.stack([d['image'] for d in features])\n",
        "            batch.update({'image': image_list})\n",
        "\n",
        "            for k in ['image_mask_label']:\n",
        "                if k in features[0] and features[0][k] is not None:\n",
        "                    image_size = batch['image'].size()\n",
        "                    mask_ratio = (random.random() * 0.25 + 0.75) * 0.999\n",
        "                    image_mask_labels = []\n",
        "                    ids_restores = []\n",
        "                    ids_keeps = []\n",
        "                    for d in features:\n",
        "                        mask, ids_restore, ids_remove, ids_keep = random_masking(int(image_size[2]**2/16**2), mask_ratio)\n",
        "                        image_mask_labels.append(mask)\n",
        "                        ids_restores.append(ids_restore)\n",
        "                        ids_keeps.append(ids_keep)\n",
        "\n",
        "                    stack_labels = torch.stack(image_mask_labels, dim=0)\n",
        "                    batch.update({'image_mask_label': stack_labels})\n",
        "                    stack_labels = torch.stack(ids_restores, dim=0)\n",
        "                    batch.update({'ids_restore': stack_labels})\n",
        "                    stack_labels = torch.stack(ids_keeps, dim=0)\n",
        "                    batch.update({'ids_keep': stack_labels})\n",
        "\n",
        "\n",
        "        return batch\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GJSMJyHwxr3W"
      },
      "source": [
        "## dataset testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lvV9UEv-mE-Z"
      },
      "outputs": [],
      "source": [
        "class DataCollatorForT5DocCLS:\n",
        "    \"\"\"\n",
        "    Data collator used for T5 document classification\n",
        "    \"\"\"\n",
        "    def __init__(self, tokenizer=None, meta_path=None, input_length=None, target_length=None, pad_token_id=None, decoder_start_token_id=None):\n",
        "\n",
        "        self.tokenizer = tokenizer #이전에 만든 udop tokenizer를 불러옴\n",
        "        self.input_length = input_length\n",
        "        self.target_length = target_length\n",
        "        self.pad_token_id = pad_token_id\n",
        "        self.decoder_start_token_id = decoder_start_token_id\n",
        "\n",
        "    def __call__(self, user_prompt ,ori_input_ids, ori_bbox_list, labels=None):\n",
        "\n",
        "        # \"원래 input text 정보 & bounding box\"\n",
        "        # -->\n",
        "        # \"prompt text 정보 + 원래 input text 정보\" list\n",
        "        # +\n",
        "        # [0,0,0,0]을 promt text token 개수만큼 + 원래 bounding box\n",
        "\n",
        "        #prompt_text = 'document classification.'\n",
        "        prompt_text = user_prompt\n",
        "        prompt_ids =  self.tokenizer.encode(prompt_text, add_special_tokens=False)\n",
        "        input_ids = prompt_ids + ori_input_ids\n",
        "        bbox_list = [[0,0,0,0]] * len(prompt_ids) + ori_bbox_list\n",
        "\n",
        "        if(labels!=None):  #label은 classification에서만 수행\n",
        "        #인줄 알았는데 layout modeling 이런것도 다 output이 있으니까 label==output 인건가..???\n",
        "          labels = self.tokenizer.encode(labels, add_special_tokens=True)\n",
        "\n",
        "        return input_ids, labels, bbox_list\n",
        "\n",
        "\n",
        "# 해당 부분은 json파일의 문장을 line-by-line으로 읽는 것으로 해당 함수 수정 완료.\n",
        "def read_ocr_core_engine(file_, image_dir, tokenizer, user_prompt, max_seq_length=None, num_img_embeds=None, image_size=224):\n",
        "    #max_seq_length와 num_img_embeds 는 원본 코드에서도 안쓰는데 왜있는거지?\n",
        "\n",
        "    with open(file_, 'r', encoding='utf8') as f:\n",
        "        try:\n",
        "            data = json.load(f)\n",
        "        except:\n",
        "            print(f\"wrong in file {file_}\")\n",
        "            data = {}\n",
        "    rets = []\n",
        "    n_split = 0\n",
        "\n",
        "\n",
        "    page_size = (1280,720)\n",
        "    #page_size = data['form'][0]['sheet_size'] #수정 필요\n",
        "\n",
        "    tiff_images =  Image.open(BytesIO(requests.get(image_dir).content))\n",
        "    image = img_trans_torchvision(tiff_images, image_size)\n",
        "\n",
        "    collator = DataCollatorForSelfSupervisedTasks(\n",
        "       tokenizer = tokenizer,\n",
        "    )\n",
        "\n",
        "    text_list, bbox_list = [], []\n",
        "    sub_text_list, sub_bbox_list, labels_list = [], [], []\n",
        "    a = 0\n",
        "    for form in data['form']: #문장별로 쪼갬\n",
        "      for word in form['words']: #단어별로 쪼갬\n",
        "\n",
        "        if word == ' ': #띄어쓰기는 건너뛰기\n",
        "          continue\n",
        "\n",
        "        sub_tokens = tokenizer.tokenize(word['text']) #단어별로 쪼갠걸 다시 토큰화 (하나의 단어도 여러개의 토큰 가능)\n",
        "        for sub_token in sub_tokens:\n",
        "          text_list.append(sub_token)\n",
        "          bbox_list.append(word['box']) #현재는 단어별 bbox, 추후 문장별 bbox로도 수정 가능\n",
        "          #bbox_list.append(form['box'])\n",
        "\n",
        "      # Labeling할 토큰들을 정한다\n",
        "      group_list, group_bbox_list = mask_process(bbox_list)\n",
        "      # sentinel token을 numbering할 list를 만들기 위해 range를 정한다\n",
        "      b = a + len(group_list)\n",
        "      # range를 토대로 numbering list를 만든다\n",
        "      numbering_list = [i for i in range(a,b)]\n",
        "      a = b\n",
        "\n",
        "      ids_list = tokenizer.convert_tokens_to_ids(text_list)\n",
        "      # 변수 설명\n",
        "      # user_prompt = 말 그대로 user_prompt\n",
        "      # ids_list = 한 문장의 token들을 index(id)로 변환한 것들을 모아놓은 리스트 (그룹화 안됨)\n",
        "      # bbox_list = 한 문장의 token들에 대응하는 bounding box를 모아놓은 리스트(그룹화 안됨)\n",
        "      # group_list = masking할 범위를 slice (e.g. [a,b]) 형태로 저장해 놓은 것들의 리스트 (그룹화 됨)\n",
        "      # group_bbox_list = group_list에 대응하는, 즉 그룹화 된 것들에 대응하는 bounding box를 모아놓은 리스트 (그룹화 됨)\n",
        "      # numbering_list = sentinel_token에 번호를 부여하기 위해 넘겨주는 리스트\n",
        "      #\n",
        "      # Collator 안에서 이 변수들을 활용하여 labeling 및 sentinel token을 붙인 후 리턴하시면 됩니다\n",
        "      # Collator에서 labeling할 때에는 ids_list, 혹은 bbox_list를 기준으로 iteration을 하되\n",
        "      # group_list를 보면서 만약 index가 group_list에 있는 slice들중 하나에 해당된다, 하면은\n",
        "      # sentinel token을 붙이고, slice에 포함된 범위는 masking한 뒤 labeling을 적절히 하시면 되겠습니다\n",
        "      input_ids, labels, bbox_list = collator(user_prompt, ids_list, bbox_list, group_list, group_bbox_list, numbering_list)\n",
        "      sub_text_list.append(input_ids)\n",
        "      sub_bbox_list.append(bbox_list)\n",
        "      labels_list.append(labels)\n",
        "      \n",
        "    if len(text_list) > 0:\n",
        "      rets.append([sub_text_list, sub_bbox_list, labels_list, image, page_size])\n",
        "\n",
        "    assert len(text_list) == len(bbox_list)\n",
        "    n_split = len(rets)\n",
        "\n",
        "    return rets, n_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "75vDHEVcxMua"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "EMPTY_BOX = [0, 0, 0, 0]\n",
        "SEP_BOX = [1000, 1000, 1000, 1000]\n",
        "\n",
        "class RvlCdipDataset(Dataset):\n",
        "\n",
        "    #NUM_LABELS = 16\n",
        "\n",
        "    def __init__(self , tokenizer , data_args , mode='train'):\n",
        "\n",
        "        \"\"\" Structure of data directory:\n",
        "\n",
        "            --- xml_sample_loc (.csv)\n",
        "                   ├── images_url\n",
        "                   └── labels_url\n",
        "            --- data (folder)\n",
        "                   └── processed_sample{index} .json\n",
        "        \"\"\"\n",
        "        self.main_df = pd.read_csv(xml_sample_loc) # xml_sample.csv 파일 저장\n",
        "\n",
        "        self.sheet_url = 'sheet_url'\n",
        "        self.image_url = 'thumbnail_url'\n",
        "\n",
        "        if mode == 'train': #train ,val, test 에 따라 사용하는 data의 범위가 다름. (근데 self-supervised도 이거 필요 있나..? )\n",
        "            file_data_range = ( 0 , int(len(self.main_df) * 0.6 ) )\n",
        "        elif mode == 'val':\n",
        "            file_data_range = ( int(len(self.main_df) * 0.6 ) , int(len(self.main_df) * 0.8 ) )\n",
        "        elif mode == 'test':\n",
        "            file_data_range = ( int(len(self.main_df) * 0.8 ) , int(len(self.main_df) ) )\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        self.cls_bbox = EMPTY_BOX[:]\n",
        "        self.pad_bbox = EMPTY_BOX[:]\n",
        "        self.sep_bbox = SEP_BOX[:]\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = data_args.max_seq_length\n",
        "        self.num_img_embeds = 0\n",
        "\n",
        "        label_list = ['a','b'] #get_rvlcdip_labels() #classification task에서만 사용하는 변수\n",
        "        self.label_list = label_list\n",
        "        self.label_map = dict(zip(list(range(len(self.label_list))), self.label_list))\n",
        "        self.n_classes = len(label_list)\n",
        "        self.label_list = label_list\n",
        "\n",
        "        self.image_size = data_args.image_size\n",
        "\n",
        "        self.examples = []\n",
        "        self.labels = []\n",
        "        self.images = []\n",
        "\n",
        "        self.cls_collator = DataCollatorForT5DocCLS( #기존에 정의한 토크나이저 선언\n",
        "                tokenizer=tokenizer,\n",
        "            )\n",
        "\n",
        "        results = [self.load_file(file_idx) for file_idx in tqdm(range(file_data_range[0],file_data_range[1]))]\n",
        "        for labels, examples, images in results:\n",
        "            self.labels += labels\n",
        "            self.examples += examples\n",
        "            self.images += images\n",
        "        assert len(self.labels) == len(self.examples)\n",
        "\n",
        "    def load_file(self, file_idx):\n",
        "\n",
        "        labels = []\n",
        "        examples = []\n",
        "        images = []\n",
        "\n",
        "        labels.append(0) ############### label 미정으로 일단 다 0 ##########\n",
        "        examples.append(f\"data/processed_sample_{file_idx}.json\")\n",
        "\n",
        "        images.append(self.main_df.iloc[file_idx][self.image_url])\n",
        "\n",
        "        return labels, examples, images\n",
        "\n",
        "    def __getitem__(self, index): #완료\n",
        "        try:\n",
        "            label = self.labels[index]\n",
        "            label = self.label_map[int(label)]\n",
        "\n",
        "            rets, n_split = read_ocr_core_engine(self.examples[index], self.images[index] , self.tokenizer, self.max_seq_length, self.num_img_embeds, self.image_size)\n",
        "\n",
        "            if n_split == 0:\n",
        "                # Something wrong with the .ocr.json file\n",
        "                print(f\"EMPTY ENTRY in index {index}\")\n",
        "                return self[(index + 1) % len(self)]\n",
        "            for i in range(n_split): #정상적으로 코드 실행됬다면 n_split==1 임.\n",
        "                text_list, bbox_list, labels, image, page_size = rets[i]\n",
        "                (width, height) = page_size\n",
        "                bbox = [  #이미지 크기에 맞게 정규화\n",
        "                    [\n",
        "                        b[0] / width,\n",
        "                        b[1] / height,\n",
        "                        b[2] / width,\n",
        "                        b[3] / height,\n",
        "                    ]\n",
        "                    for b in bbox_list\n",
        "                ]\n",
        "\n",
        "                visual_bbox_input = get_visual_bbox(self.image_size) # (x_min, y_min, x_max, y_max) 형태의 좌표로 이루어진 텐서 반환\n",
        "\n",
        "                attention_mask = [1] * len(input_ids)\n",
        "                decoder_attention_mask = [1] * len(labels)\n",
        "\n",
        "                char_list = [0]\n",
        "                char_bbox_list = [[0,0,0,0]]\n",
        "                char_ids = torch.tensor(char_list, dtype=torch.long)\n",
        "                char_bbox_input = torch.tensor(char_bbox_list, dtype=torch.float)\n",
        "\n",
        "                bbox_input = torch.tensor(bbox_input, dtype=torch.float)\n",
        "                labels = torch.tensor(labels, dtype=torch.long)\n",
        "                input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
        "                attention_mask = torch.tensor(attention_mask, dtype=torch.long)\n",
        "                decoder_attention_mask = torch.tensor(decoder_attention_mask, dtype=torch.long)\n",
        "                assert len(bbox_input) == len(input_ids)\n",
        "                assert len(bbox_input.size()) == 2\n",
        "                assert len(char_bbox_input.size()) == 2\n",
        "\n",
        "                return_dict =  {\n",
        "                    \"input_ids\": input_ids,\n",
        "                    \"attention_mask\": attention_mask,\n",
        "                    \"labels\": labels,\n",
        "                    \"seg_data\": bbox_input,\n",
        "                    \"visual_seg_data\": visual_bbox_input,\n",
        "                    \"decoder_attention_mask\": decoder_attention_mask,\n",
        "                    \"image\": image,\n",
        "                    'char_ids': char_ids,\n",
        "                    'char_seg_data': char_bbox_input\n",
        "                }\n",
        "                assert input_ids is not None\n",
        "\n",
        "                return return_dict\n",
        "        except: #오류가 났다는 거는 파일이 없다는 것. 해당 상황에서는 index+1 파일 불러오는 것으로 대체\n",
        "            print(f\"{index} 파일을 {index+1}로 대체\")\n",
        "            return self.__getitem__(index+1)\n",
        "\n",
        "            #return self[(index + 1) % len(self)]\n",
        "\n",
        "    #def get_labels(self): # classification에서 label의 종류 출력하는 함수. 우리는 필요 없을 듯.\n",
        "    #    return list(map(str, list(range(self.NUM_LABELS))))\n",
        "\n",
        "    def pad_tokens(self, input_ids, bbox): #이건 그냥 길이 max_len에 맞게 맞추는 함수\n",
        "        # [CLS], sentence, [SEP]\n",
        "        tokenized_tokens = self.tokenizer.build_inputs_with_special_tokens(input_ids)\n",
        "        start_token, _, end_token = tokenized_tokens[0], tokenized_tokens[1:-1], tokenized_tokens[-1]\n",
        "\n",
        "        sentence = tokenized_tokens\n",
        "        expected_seq_length = self.max_seq_length - self.num_img_embeds\n",
        "        mask = torch.zeros(expected_seq_length)\n",
        "        mask[:len(sentence)] = 1\n",
        "\n",
        "        bbox = [self.cls_bbox] + bbox + [self.sep_bbox]\n",
        "        while len(sentence) < expected_seq_length:\n",
        "            sentence.append(self.tokenizer.pad_token_id)\n",
        "            bbox.append(self.pad_bbox)\n",
        "\n",
        "        assert len(sentence) == len(bbox)\n",
        "        return (sentence, mask, bbox, start_token, end_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaFw9cerx47g",
        "outputId": "9df9073e-8ec1-4dc4-ad55-dc5b36006db0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1844/1844 [00:00<00:00, 12014.35it/s]\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "\n",
        "# data_args를 Namespace 객체로 변환합니다.\n",
        "data_args = argparse.Namespace(\n",
        "    max_seq_length=500,\n",
        "    image_size=224\n",
        ")\n",
        "#json 하나로 묶어서 pikkle로 대체\n",
        "my_tokenizer = UdopTokenizer.from_pretrained(\"tokenizer_finetuned_ket5_by_xml_data\")\n",
        "\n",
        "dataset = RvlCdipDataset( my_tokenizer , data_args , mode='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrJGXFgB3K1H",
        "outputId": "3d2e5f38-d4b7-43cc-ac35-2c0e4bd7b3bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4 파일을 5로 대체\n",
            "8 파일을 9로 대체\n",
            "13 파일을 14로 대체\n",
            "44 파일을 45로 대체\n",
            "80 파일을 81로 대체\n",
            "82 파일을 83로 대체\n",
            "84 파일을 85로 대체\n",
            "EMPTY ENTRY in index 86\n",
            "86 파일을 87로 대체\n",
            "382 파일을 383로 대체\n",
            "486 파일을 487로 대체\n",
            "wrong in file data/processed_sample_583.json\n",
            "583 파일을 584로 대체\n",
            "wrong in file data/processed_sample_587.json\n",
            "587 파일을 588로 대체\n"
          ]
        }
      ],
      "source": [
        "for i in range(1844):\n",
        "  x = dataset.__getitem__(i)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A9hb-4We7vfY"
      },
      "source": [
        "# Dataset class loading을 위한 class들 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8pWwyAbh7zPU"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5TokenizerFast, PreTrainedTokenizer, PreTrainedTokenizerBase\n",
        "\n",
        "import re\n",
        "import sentencepiece as spm\n",
        "\n",
        "# The special tokens of T5Tokenizer is hard-coded with <extra_id_{}>\n",
        "# Created another class UDOPTokenizer extending it to add special visual tokens like <loc_{}>, etc.\n",
        "\n",
        "#class UdopTokenizer(T5Tokenizer):\n",
        "class UdopTokenizer(AutoTokenizer):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_file,\n",
        "        eos_token=\"</s>\",\n",
        "        unk_token=\"<unk>\",\n",
        "        pad_token=\"<pad>\",\n",
        "        extra_ids=100,\n",
        "        loc_extra_ids=501,\n",
        "        other_extra_ids=200,\n",
        "        additional_special_tokens=[],\n",
        "        sp_model_kwargs=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        # Add extra_ids to the special token list\n",
        "        if extra_ids > 0 and not \"<extra_id_0>\" in additional_special_tokens:\n",
        "            additional_special_tokens = [\"<extra_id_{}>\".format(i) for i in range(extra_ids)]\n",
        "            additional_special_tokens.extend([\"<extra_l_id_{}>\".format(i) for i in range(extra_ids)])\n",
        "            additional_special_tokens.extend([\"</extra_l_id_{}>\".format(i) for i in range(extra_ids)])\n",
        "            additional_special_tokens.extend([\"<extra_t_id_{}>\".format(i) for i in range(extra_ids)])\n",
        "            additional_special_tokens.extend([\"</extra_t_id_{}>\".format(i) for i in range(extra_ids)])\n",
        "\n",
        "        if loc_extra_ids > 0 and not \"<loc_0>\" in additional_special_tokens:\n",
        "            additional_special_tokens.extend([\"<loc_{}>\".format(i) for i in range(loc_extra_ids)])\n",
        "\n",
        "        if other_extra_ids > 0 and not \"<other_0>\" in additional_special_tokens:\n",
        "            additional_special_tokens.extend([\"<other_{}>\".format(i) for i in range(other_extra_ids)])\n",
        "        print(additional_special_tokens)\n",
        "        PreTrainedTokenizer.__init__(\n",
        "            self,\n",
        "            eos_token=eos_token,\n",
        "            unk_token=unk_token,\n",
        "            pad_token=pad_token,\n",
        "            extra_ids=extra_ids,\n",
        "            additional_special_tokens=additional_special_tokens,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        self.sp_model_kwargs = {} if sp_model_kwargs is None else sp_model_kwargs\n",
        "\n",
        "        self.vocab_file = vocab_file\n",
        "        self._extra_ids = extra_ids\n",
        "        self._loc_extra_ids = loc_extra_ids\n",
        "        self._other_extra_ids = other_extra_ids\n",
        "\n",
        "        self.sp_model = spm.SentencePieceProcessor(**self.sp_model_kwargs)\n",
        "        self.sp_model.Load(vocab_file)\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return self.sp_model.get_piece_size() + self._extra_ids * 5 + self._loc_extra_ids + self._other_extra_ids\n",
        "\n",
        "    def get_vocab(self):\n",
        "        vocab = {self.convert_ids_to_tokens(\n",
        "            i): i for i in range(self.vocab_size)}\n",
        "        vocab.update(self.added_tokens_encoder)\n",
        "        return vocab\n",
        "\n",
        "    def _convert_token_to_id(self, token):\n",
        "        \"\"\" Converts a token (str) in an id using the vocab. \"\"\"\n",
        "        if token.startswith(\"<extra_id_\"):\n",
        "            match = re.match(r\"<extra_id_(\\d+)>\", token)\n",
        "            num = int(match.group(1))\n",
        "            return self.vocab_size - num - 1 - self._other_extra_ids - self._loc_extra_ids - self._extra_ids * 4\n",
        "        elif token.startswith(\"<extra_l_id_\"):\n",
        "            match = re.match(r\"<extra_l_id_(\\d+)>\", token)\n",
        "            num = int(match.group(1))\n",
        "            return self.vocab_size - num - 1 - self._other_extra_ids - self._loc_extra_ids - self._extra_ids * 3\n",
        "        elif token.startswith(\"</extra_l_id_\"):\n",
        "            match = re.match(r\"</extra_l_id_(\\d+)>\", token)\n",
        "            num = int(match.group(1))\n",
        "            return self.vocab_size - num - 1 - self._other_extra_ids - self._loc_extra_ids - self._extra_ids * 2\n",
        "        elif token.startswith(\"<extra_t_id_\"):\n",
        "            match = re.match(r\"<extra_t_id_(\\d+)>\", token)\n",
        "            num = int(match.group(1))\n",
        "            return self.vocab_size - num - 1 - self._other_extra_ids - self._loc_extra_ids - self._extra_ids\n",
        "        elif token.startswith(\"</extra_t_id_\"):\n",
        "            match = re.match(r\"</extra_t_id_(\\d+)>\", token)\n",
        "            num = int(match.group(1))\n",
        "            return self.vocab_size - num - 1 - self._other_extra_ids - self._loc_extra_ids\n",
        "        elif token.startswith(\"<loc_\"):\n",
        "            match = re.match(r\"<loc_(\\d+)>\", token)\n",
        "            num = int(match.group(1))\n",
        "            return self.vocab_size - num - 1 - self._other_extra_ids\n",
        "        elif token.startswith(\"<other_\"):\n",
        "            match = re.match(r\"<other_(\\d+)>\", token)\n",
        "            num = int(match.group(1))\n",
        "            return self.vocab_size - num - 1\n",
        "\n",
        "        return self.sp_model.piece_to_id(token)\n",
        "\n",
        "    def _convert_id_to_token(self, index):\n",
        "        \"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"\n",
        "        if index < self.sp_model.get_piece_size():\n",
        "            token = self.sp_model.IdToPiece(index)\n",
        "        else:\n",
        "\n",
        "            if index > self.sp_model.get_piece_size() + self._extra_ids * 5 + self._loc_extra_ids - 1:\n",
        "                index_loc = self.vocab_size - 1 - index\n",
        "                token = f\"<other_{index_loc}>\"\n",
        "            elif index > self.sp_model.get_piece_size() + self._extra_ids * 5 - 1:\n",
        "                index_loc = self.vocab_size - self._other_extra_ids - 1 - index\n",
        "                token = f\"<loc_{index_loc}>\"\n",
        "            elif index > self.sp_model.get_piece_size() + self._extra_ids * 4 - 1:\n",
        "                token = \"</extra_t_id_{}>\".format(self.vocab_size - self._other_extra_ids - self._loc_extra_ids - 1 - index)\n",
        "            elif index > self.sp_model.get_piece_size() + self._extra_ids * 3 - 1:\n",
        "                token = \"<extra_t_id_{}>\".format(self.vocab_size - self._other_extra_ids - self._loc_extra_ids - self._extra_ids - 1 - index)\n",
        "            elif index > self.sp_model.get_piece_size() + self._extra_ids * 2 - 1:\n",
        "                token = \"</extra_l_id_{}>\".format(self.vocab_size - self._other_extra_ids - self._loc_extra_ids - self._extra_ids * 2 - 1 - index)\n",
        "            elif index > self.sp_model.get_piece_size() + self._extra_ids - 1:\n",
        "                token = \"<extra_l_id_{}>\".format(self.vocab_size - self._other_extra_ids - self._loc_extra_ids - self._extra_ids * 3 - 1 - index)\n",
        "            elif index > self.sp_model.get_piece_size() - 1:\n",
        "                token = \"<extra_id_{}>\".format(self.vocab_size - self._other_extra_ids - self._loc_extra_ids - self._extra_ids * 4 - 1 - index)\n",
        "            else:\n",
        "                raise\n",
        "        return token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ukqglKDV8GOq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ByUFkKAn8J3g"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "    codes for just preprocessing\n",
        "\"\"\"\n",
        "\n",
        "def normalText(t):\n",
        "    if type(t) is float:\n",
        "        if t == int(t):\n",
        "            t = int(t)\n",
        "    t = str(t)\n",
        "    return t.strip()\n",
        "\n",
        "\n",
        "def get_prop(node, name):\n",
        "    title = node.get(\"title\")\n",
        "    props = title.split(\";\")\n",
        "    for prop in props:\n",
        "        (key, args) = prop.split(None, 1)\n",
        "        args = args.strip('\"')\n",
        "        if key == name:\n",
        "            return args\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_bb(bb):\n",
        "    bbs = [float(j) for j in bb]\n",
        "    xs, ys = [], []\n",
        "    for i, b in enumerate(bbs):\n",
        "        if i % 2 == 0:\n",
        "            xs.append(b)\n",
        "        else:\n",
        "            ys.append(b)\n",
        "    return [min(xs), min(ys), max(xs), max(ys)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pqyT6gHj8J3g"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms import functional as F\n",
        "\n",
        "\"\"\"\n",
        "    codes for just preprocessing image data\n",
        "\"\"\"\n",
        "def get_visual_bbox(image_size=224):\n",
        "    image_feature_pool_shape = [image_size//16, image_size//16]\n",
        "    visual_bbox_x = (torch.arange(\n",
        "        0,\n",
        "        1.0 * (image_feature_pool_shape[1] + 1),\n",
        "        1.0,\n",
        "    ) / image_feature_pool_shape[1])\n",
        "    visual_bbox_y = (torch.arange(\n",
        "        0,\n",
        "        1.0 * (image_feature_pool_shape[0] + 1),\n",
        "        1.0,\n",
        "    ) / image_feature_pool_shape[0])\n",
        "    visual_bbox_input = torch.stack(\n",
        "        [\n",
        "            visual_bbox_x[:-1].repeat(\n",
        "                image_feature_pool_shape[0], 1),\n",
        "            visual_bbox_y[:-1].repeat(\n",
        "                image_feature_pool_shape[1], 1).transpose(\n",
        "                    0, 1),\n",
        "            visual_bbox_x[1:].repeat(\n",
        "                image_feature_pool_shape[0], 1),\n",
        "            visual_bbox_y[1:].repeat(\n",
        "                image_feature_pool_shape[1], 1).transpose(\n",
        "                    0, 1),\n",
        "        ],\n",
        "        dim=-1,\n",
        "    ).view(-1, 4)\n",
        "    return visual_bbox_input\n",
        "\n",
        "class Normalize(object):\n",
        "    def __init__(self, mean, std, format='rgb'):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.format = format.lower()\n",
        "\n",
        "    def __call__(self, image):\n",
        "        if 'bgr' in self.format:\n",
        "            image = image[[2, 1, 0]]\n",
        "        if '255' in self.format:\n",
        "            image = image * 255\n",
        "        if image.size(0) == 1:\n",
        "            image = image.repeat(3, 1, 1)\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image\n",
        "\n",
        "def img_trans_torchvision(image, image_size=224):\n",
        "    trans = T.Compose([\n",
        "            T.Resize([image_size,image_size]),\n",
        "            T.ToTensor(),\n",
        "            Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )])\n",
        "\n",
        "    image = trans(image)  # copy to make it writeable\n",
        "    return image"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iRypfVcFCyk3"
      },
      "source": [
        "#json 파일 최적화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MukbMyRSDeIX",
        "outputId": "34285550-0c64-4158-fafa-94ebe81a6f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(xml_sample_loc)\n",
        "\n",
        "json_sum = []\n",
        "\n",
        "for i in range(len(df)):\n",
        "\n",
        "    if(i%100==0):\n",
        "      print(i)\n",
        "\n",
        "    try:\n",
        "      file_ = (f\"data/processed_sample_{i}.json\")\n",
        "\n",
        "      with open(file_, 'r', encoding='utf8') as f:\n",
        "         data = json.load(f)\n",
        "\n",
        "      json_sum.append(data)\n",
        "\n",
        "    except:\n",
        "\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CUZqL-4ZEaUV"
      },
      "outputs": [],
      "source": [
        "filename = f\"sumall_processed_sample.json\"\n",
        "with open(filename, \"w\") as file_:\n",
        "    json.dump(json_sum , file_ , indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EndEG65XE0IW"
      },
      "outputs": [],
      "source": [
        "for i in range(len(df)):\n",
        "  try:\n",
        "    image_url = 'thumbnail_url'\n",
        "    url = df.iloc[i][image_url]\n",
        "    tiff_image =  Image.open(BytesIO(requests.get(url).content))\n",
        "\n",
        "    png_image_path = f\"image/image_{i}.png\"\n",
        "    tiff_image.save(png_image_path, \"PNG\")\n",
        "  except:\n",
        "    continue"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Zb-9YdQ_Bc16",
        "12wBJAggBwBt",
        "3poxvfRhCXI5",
        "66ZWFovSCkOZ",
        "f5L7gXTnDM9K",
        "LmJo1DsmEAev",
        "r2IgTNFREGiV",
        "MuEpv5Nlh5T2",
        "fMEq4ONo6qKx",
        "5S3ZNoZQ6zNl",
        "EhwgfrlO64pu",
        "ENujqg_z68np",
        "zzxQlolUvU4E",
        "lw0f6QNV7wKy",
        "PLzhr1Hd72Bq",
        "GJSMJyHwxr3W",
        "A9hb-4We7vfY"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
